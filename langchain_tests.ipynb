{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e0ac80d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "openai_api_key = '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'  # Replace with your actual API key"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a248983c",
   "metadata": {},
   "source": [
    "## Basic #1: Chat messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "802e687a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.schema import HumanMessage, SystemMessage, AIMessage\n",
    "\n",
    "chat = ChatOpenAI(temperature=0, openai_api_key=openai_api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e3ec426",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat(\n",
    "    [\n",
    "        SystemMessage(content=\"You are a funny AI bot that helps a user figure out what to eat in 2 short sentences\"),\n",
    "        HumanMessage(content=\"I like tomatoes, what should I eat?\")\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88ec22f8",
   "metadata": {},
   "source": [
    "## Basic #2: Documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba462886",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.schema import Document\n",
    "\n",
    "Document(page_content=\"This is my document. It is full of text that I've gathered from other places\",\n",
    "         metadata={\n",
    "             'my_document_id' : 234234,\n",
    "             'my_document_source' : \"The LangChain Papers\",\n",
    "             'my_document_create_time' : 1680013019\n",
    "         })"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62550491",
   "metadata": {},
   "source": [
    "## Basic #3: Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90b17026",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "\n",
    "embeddings = OpenAIEmbeddings(openai_api_key=openai_api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1878d728",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"This is my document. It is full of text that I've gathered from other places\"\n",
    "text_embedding = embeddings.embed_query(text)\n",
    "print (f\"Your embedding is length {len(text_embedding)}\")\n",
    "print (f\"Here's a sample: {text_embedding[:5]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6594d75",
   "metadata": {},
   "source": [
    "## Basic #4: Prompt templates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b60bd11b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms import OpenAI\n",
    "from langchain import PromptTemplate\n",
    "\n",
    "\n",
    "llm = OpenAI(model_name=\"text-davinci-003\", openai_api_key=openai_api_key)\n",
    "\n",
    "# Notice \"location\" below, that is a placeholder for another value later\n",
    "template = \"\"\"\n",
    "I really want to travel to {location}. What should I do there?\n",
    "\n",
    "Respond in one short sentence\n",
    "\"\"\"\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    input_variables=[\"location\"],\n",
    "    template=template,\n",
    ")\n",
    "\n",
    "final_prompt = prompt.format(location='Rome')\n",
    "\n",
    "print (f\"Final Prompt: {final_prompt}\")\n",
    "print (\"-----------\")\n",
    "print (f\"LLM Output: {llm(final_prompt)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c9f4732",
   "metadata": {},
   "source": [
    "## Basics #5: Few shot example selector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd3f872e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts.example_selector import SemanticSimilarityExampleSelector\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.prompts import FewShotPromptTemplate, PromptTemplate\n",
    "from langchain.llms import OpenAI\n",
    "\n",
    "llm = OpenAI(model_name=\"text-davinci-003\", openai_api_key=openai_api_key, temperature=0)\n",
    "\n",
    "example_prompt = PromptTemplate(\n",
    "    input_variables=[\"input\", \"output\"],\n",
    "    template=\"Example Input: {input}\\nExample Output: {output}\",\n",
    ")\n",
    "\n",
    "# Examples of locations that nouns are found\n",
    "examples = [\n",
    "    {\"input\": \"pirate\", \"output\": \"ship\"},\n",
    "    {\"input\": \"pilot\", \"output\": \"plane\"},\n",
    "    {\"input\": \"driver\", \"output\": \"car\"},\n",
    "    {\"input\": \"tree\", \"output\": \"ground\"},\n",
    "    {\"input\": \"bird\", \"output\": \"nest\"},\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f041d422",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SemanticSimilarityExampleSelector will select examples that are similar to your input by semantic meaning\n",
    "\n",
    "example_selector = SemanticSimilarityExampleSelector.from_examples(\n",
    "    # This is the list of examples available to select from.\n",
    "    examples, \n",
    "    \n",
    "    # This is the embedding class used to produce embeddings which are used to measure semantic similarity.\n",
    "    OpenAIEmbeddings(openai_api_key=openai_api_key), \n",
    "    \n",
    "    # This is the VectorStore class that is used to store the embeddings and do a similarity search over.\n",
    "    FAISS, \n",
    "    \n",
    "    # This is the number of examples to produce.\n",
    "    k=5\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5365fbd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "similar_prompt = FewShotPromptTemplate(\n",
    "    # The object that will help select examples\n",
    "    example_selector=example_selector,\n",
    "    \n",
    "    # Your prompt\n",
    "    example_prompt=example_prompt,\n",
    "    \n",
    "    # Customizations that will be added to the top and bottom of your prompt\n",
    "    prefix=\"Give the location an item is usually found in\",\n",
    "    suffix=\"Input: {noun}\\nOutput:\",\n",
    "    \n",
    "    # What inputs your prompt will receive\n",
    "    input_variables=[\"noun\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e06c38b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select a noun!\n",
    "my_noun = \"headphone\"\n",
    "\n",
    "print(similar_prompt.format(noun=my_noun))\n",
    "llm(similar_prompt.format(noun=my_noun))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b36ae4b",
   "metadata": {},
   "source": [
    "## Basics #6: Output parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa92cd40",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.output_parsers import StructuredOutputParser, ResponseSchema\n",
    "from langchain.prompts import ChatPromptTemplate, HumanMessagePromptTemplate\n",
    "from langchain.llms import OpenAI\n",
    "\n",
    "llm = OpenAI(model_name=\"text-davinci-003\", openai_api_key=openai_api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d6f1097",
   "metadata": {},
   "outputs": [],
   "source": [
    "# How you would like your response structured. This is basically a fancy prompt template\n",
    "response_schemas = [\n",
    "    ResponseSchema(name=\"bad_string\", description=\"This a poorly formatted user input string\"),\n",
    "    ResponseSchema(name=\"good_string\", description=\"This is your response, a reformatted response\")\n",
    "]\n",
    "\n",
    "# How you would like to parse your output\n",
    "output_parser = StructuredOutputParser.from_response_schemas(response_schemas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e17e76f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# See the prompt template you created for formatting\n",
    "format_instructions = output_parser.get_format_instructions()\n",
    "print (format_instructions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f81f075",
   "metadata": {},
   "outputs": [],
   "source": [
    "template = \"\"\"\n",
    "You will be given a poorly formatted string from a user.\n",
    "Reformat it and make sure all the words are spelled correctly. Also add 1 more sentence to it.\n",
    "\n",
    "{format_instructions}\n",
    "\n",
    "% USER INPUT:\n",
    "{user_input}\n",
    "\n",
    "YOUR RESPONSE:\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    input_variables=[\"user_input\"],\n",
    "    partial_variables={\"format_instructions\": format_instructions},\n",
    "    template=template\n",
    ")\n",
    "\n",
    "promptValue = prompt.format(user_input=\"it was a hot summer night i get up!\")\n",
    "\n",
    "print(promptValue)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f6dbeca",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(promptValue)\n",
    "llm_output = llm(promptValue)\n",
    "llm_output\n",
    "output_parser.parse(llm_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4312cd9b",
   "metadata": {},
   "source": [
    "## Basics #7: Document loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "296f02b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import HNLoader\n",
    "\n",
    "loader = HNLoader(\"https://news.ycombinator.com/item?id=34422627\")\n",
    "\n",
    "data = loader.load()\n",
    "print (f\"Found {len(data)} comments\")\n",
    "print (f\"Here's a sample:\\n\\n{''.join([x.page_content[:150] for x in data[:2]])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6600989",
   "metadata": {},
   "source": [
    "### 7.1 Text splitters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42e34c7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "# This is a long document we can split up.\n",
    "with open('data/charlie_txt.txt') as f:\n",
    "    pg_work = f.read()\n",
    "    \n",
    "print (f\"You have {len([pg_work])} document\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3040e49",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    # Set a really small chunk size, just to show.\n",
    "    chunk_size = 150,\n",
    "    chunk_overlap  = 20,\n",
    ")\n",
    "\n",
    "texts = text_splitter.create_documents([pg_work])\n",
    "print (f\"You have {len(texts)} documents\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0680b4d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print (\"Preview:\")\n",
    "print (texts[0].page_content, \"\\n\")\n",
    "print (texts[1].page_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d21ec7b",
   "metadata": {},
   "source": [
    "### 7.2 Retrievers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63e20a56",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import TextLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "\n",
    "loader = TextLoader('data/charlie_txt.txt')\n",
    "documents = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77e271df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get your splitter ready\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=50)\n",
    "\n",
    "# Split your docs into texts\n",
    "texts = text_splitter.split_documents(documents)\n",
    "print(len(texts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0343940",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get embedding engine ready\n",
    "embeddings = OpenAIEmbeddings(openai_api_key=openai_api_key)\n",
    "\n",
    "# Embedd your texts\n",
    "db = FAISS.from_documents(texts, embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13d0b8e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cec7e0c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Embedd your texts\n",
    "db = FAISS.from_documents(texts, embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72b4654b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Init your retriever. Asking for just 1 document back\n",
    "retriever = db.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49484966",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd4b0482",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = retriever.get_relevant_documents(\"what types of things did the author want to build?\")\n",
    "print(\"\\n\\n\".join([x.page_content[:200] for x in docs[:2]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4acf6701",
   "metadata": {},
   "source": [
    "## Basics #8: Memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff9b3043",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.memory import ChatMessageHistory\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "\n",
    "chat = ChatOpenAI(temperature=0, openai_api_key=openai_api_key)\n",
    "\n",
    "history = ChatMessageHistory()\n",
    "\n",
    "history.add_ai_message(\"hi!\")\n",
    "\n",
    "history.add_user_message(\"what is the capital of france?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "617ee5a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "history.messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abe4d005",
   "metadata": {},
   "outputs": [],
   "source": [
    "ai_response = chat(history.messages)\n",
    "ai_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25929317",
   "metadata": {},
   "outputs": [],
   "source": [
    "history.add_ai_message(ai_response.content)\n",
    "history.messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3222cf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "history.add_user_message(\"what's there to see and do?\")\n",
    "ai_response = chat(history.messages)\n",
    "\n",
    "from IPython.display import display\n",
    "display(ai_response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c02e2709",
   "metadata": {},
   "source": [
    "## Basics #9: Chains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27ded48a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms import OpenAI\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import SimpleSequentialChain\n",
    "\n",
    "llm = OpenAI(temperature=1, openai_api_key=openai_api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7f55b41",
   "metadata": {},
   "outputs": [],
   "source": [
    "template = \"\"\"Your job is to come up with a classic dish from the area that the users suggests.\n",
    "% USER LOCATION\n",
    "{user_location}\n",
    "\n",
    "YOUR RESPONSE:\n",
    "\"\"\"\n",
    "prompt_template = PromptTemplate(input_variables=[\"user_location\"], template=template)\n",
    "\n",
    "# Holds my 'location' chain\n",
    "location_chain = LLMChain(llm=llm, prompt=prompt_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6ca4f09",
   "metadata": {},
   "outputs": [],
   "source": [
    "template = \"\"\"Given a meal, give a short and simple recipe on how to make that dish at home.\n",
    "% MEAL\n",
    "{user_meal}\n",
    "\n",
    "YOUR RESPONSE:\n",
    "\"\"\"\n",
    "prompt_template = PromptTemplate(input_variables=[\"user_meal\"], template=template)\n",
    "\n",
    "# Holds my 'meal' chain\n",
    "meal_chain = LLMChain(llm=llm, prompt=prompt_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5c4424a",
   "metadata": {},
   "outputs": [],
   "source": [
    "overall_chain = SimpleSequentialChain(chains=[location_chain, meal_chain], verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9d188a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "review = overall_chain.run(\"Hong Kong\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34ebb5c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains.summarize import load_summarize_chain\n",
    "from langchain.document_loaders import TextLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "loader = TextLoader('data/charlie_txt.txt')\n",
    "documents = loader.load()\n",
    "\n",
    "# Get your splitter ready\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=700, chunk_overlap=50)\n",
    "\n",
    "# Split your docs into texts\n",
    "texts = text_splitter.split_documents(documents)\n",
    "\n",
    "# There is a lot of complexity hidden in this one line. I encourage you to check out the video above for more detail\n",
    "chain = load_summarize_chain(llm, chain_type=\"map_reduce\", verbose=True)\n",
    "chain.run(texts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14b8c731",
   "metadata": {},
   "source": [
    "## Basics #10: Agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e57543f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import load_tools\n",
    "from langchain.agents import initialize_agent\n",
    "from langchain.llms import OpenAI\n",
    "import json\n",
    "\n",
    "llm = OpenAI(temperature=0, openai_api_key=openai_api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e52fb5be",
   "metadata": {},
   "outputs": [],
   "source": [
    "serpapi_api_key='9e35ac3794ca30c2de171306f4158424bbe104cf3140cadd1b833e6a4ac413e7'\n",
    "\n",
    "toolkit = load_tools([\"serpapi\"], llm=llm, serpapi_api_key=serpapi_api_key)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77982b15",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = initialize_agent(toolkit, llm, agent=\"zero-shot-react-description\", verbose=True, return_intermediate_steps=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7230f16",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = agent({\"input\":\"what was the first album of the\" \n",
    "                    \"band that Natalie Bergman is a part of?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1a76b5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "response[\"intermediate_steps\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07bfa78f",
   "metadata": {},
   "outputs": [],
   "source": [
    "json.dumps(response[\"intermediate_steps\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd55b94a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
