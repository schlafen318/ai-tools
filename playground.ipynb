{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b12e32ae7c7e4f6990605f6bfd5cb5b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)lve/main/config.json:   0%|          | 0.00/1.58k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "48013efaa5174e909732d3849faab7bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading pytorch_model.bin:   0%|          | 0.00/1.63G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "000fc60ef4594db092be3b7e9688af47",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)neration_config.json:   0%|          | 0.00/363 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f05d8d7299034ab2ab1059003b0cc5de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)olve/main/vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "079a11df63b44afab6a214116b7714ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)olve/main/merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b2b890eea1bc4339a2d5b8493f727e46",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)/main/tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'summary_text': 'Liana Barrientos, 39, is charged with two counts of \"offering a false instrument for filing in the first degree\" In total, she has been married 10 times, with nine of her marriages occurring between 1999 and 2002. She is believed to still be married to four men.'}]\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "summarizer = pipeline(\"summarization\", model=\"facebook/bart-large-cnn\")\n",
    "\n",
    "ARTICLE = \"\"\" New York (CNN)When Liana Barrientos was 23 years old, she got married in Westchester County, New York.\n",
    "A year later, she got married again in Westchester County, but to a different man and without divorcing her first husband.\n",
    "Only 18 days after that marriage, she got hitched yet again. Then, Barrientos declared \"I do\" five more times, sometimes only within two weeks of each other.\n",
    "In 2010, she married once more, this time in the Bronx. In an application for a marriage license, she stated it was her \"first and only\" marriage.\n",
    "Barrientos, now 39, is facing two criminal counts of \"offering a false instrument for filing in the first degree,\" referring to her false statements on the\n",
    "2010 marriage license application, according to court documents.\n",
    "Prosecutors said the marriages were part of an immigration scam.\n",
    "On Friday, she pleaded not guilty at State Supreme Court in the Bronx, according to her attorney, Christopher Wright, who declined to comment further.\n",
    "After leaving court, Barrientos was arrested and charged with theft of service and criminal trespass for allegedly sneaking into the New York subway through an emergency exit, said Detective\n",
    "Annette Markowski, a police spokeswoman. In total, Barrientos has been married 10 times, with nine of her marriages occurring between 1999 and 2002.\n",
    "All occurred either in Westchester County, Long Island, New Jersey or the Bronx. She is believed to still be married to four men, and at one time, she was married to eight men at once, prosecutors say.\n",
    "Prosecutors said the immigration scam involved some of her husbands, who filed for permanent residence status shortly after the marriages.\n",
    "Any divorces happened only after such filings were approved. It was unclear whether any of the men will be prosecuted.\n",
    "The case was referred to the Bronx District Attorney\\'s Office by Immigration and Customs Enforcement and the Department of Homeland Security\\'s\n",
    "Investigation Division. Seven of the men are from so-called \"red-flagged\" countries, including Egypt, Turkey, Georgia, Pakistan and Mali.\n",
    "Her eighth husband, Rashid Rajput, was deported in 2006 to his native Pakistan after an investigation by the Joint Terrorism Task Force.\n",
    "If convicted, Barrientos faces up to four years in prison.  Her next court appearance is scheduled for May 18.\n",
    "\"\"\"\n",
    "print(summarizer(ARTICLE, max_length=130, min_length=30, do_sample=False))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (12717 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index out of range in self",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 276\u001b[0m\n\u001b[1;32m      1\u001b[0m ARTICLE \u001b[39m=\u001b[39m \u001b[39m\"\"\"\u001b[39m\n\u001b[1;32m      2\u001b[0m \u001b[39mMicrosoft FY23 Fourth Quarter Earnings Conference Call\u001b[39m\n\u001b[1;32m      3\u001b[0m \u001b[39mBrett Iversen, Satya Nadella, Amy Hood\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    274\u001b[0m \n\u001b[1;32m    275\u001b[0m \u001b[39m\"\"\"\u001b[39m\n\u001b[0;32m--> 276\u001b[0m \u001b[39mprint\u001b[39m(summarizer(ARTICLE, max_length\u001b[39m=\u001b[39;49m\u001b[39m130\u001b[39;49m, min_length\u001b[39m=\u001b[39;49m\u001b[39m30\u001b[39;49m, do_sample\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m))\n",
      "File \u001b[0;32m~/Documents/GitHub/ai-tools/.venv/lib/python3.11/site-packages/transformers/pipelines/text2text_generation.py:265\u001b[0m, in \u001b[0;36mSummarizationPipeline.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    241\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m    242\u001b[0m \u001b[39m    \u001b[39m\u001b[39mr\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    243\u001b[0m \u001b[39m    Summarize the text(s) given as inputs.\u001b[39;00m\n\u001b[1;32m    244\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    263\u001b[0m \u001b[39m          ids of the summary.\u001b[39;00m\n\u001b[1;32m    264\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 265\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__call__\u001b[39;49m(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/Documents/GitHub/ai-tools/.venv/lib/python3.11/site-packages/transformers/pipelines/text2text_generation.py:165\u001b[0m, in \u001b[0;36mText2TextGenerationPipeline.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    136\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m    137\u001b[0m \u001b[39m    \u001b[39m\u001b[39mr\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    138\u001b[0m \u001b[39m    Generate the output text(s) using text(s) given as inputs.\u001b[39;00m\n\u001b[1;32m    139\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    162\u001b[0m \u001b[39m          ids of the generated text.\u001b[39;00m\n\u001b[1;32m    163\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 165\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__call__\u001b[39;49m(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    166\u001b[0m     \u001b[39mif\u001b[39;00m (\n\u001b[1;32m    167\u001b[0m         \u001b[39misinstance\u001b[39m(args[\u001b[39m0\u001b[39m], \u001b[39mlist\u001b[39m)\n\u001b[1;32m    168\u001b[0m         \u001b[39mand\u001b[39;00m \u001b[39mall\u001b[39m(\u001b[39misinstance\u001b[39m(el, \u001b[39mstr\u001b[39m) \u001b[39mfor\u001b[39;00m el \u001b[39min\u001b[39;00m args[\u001b[39m0\u001b[39m])\n\u001b[1;32m    169\u001b[0m         \u001b[39mand\u001b[39;00m \u001b[39mall\u001b[39m(\u001b[39mlen\u001b[39m(res) \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m \u001b[39mfor\u001b[39;00m res \u001b[39min\u001b[39;00m result)\n\u001b[1;32m    170\u001b[0m     ):\n\u001b[1;32m    171\u001b[0m         \u001b[39mreturn\u001b[39;00m [res[\u001b[39m0\u001b[39m] \u001b[39mfor\u001b[39;00m res \u001b[39min\u001b[39;00m result]\n",
      "File \u001b[0;32m~/Documents/GitHub/ai-tools/.venv/lib/python3.11/site-packages/transformers/pipelines/base.py:1120\u001b[0m, in \u001b[0;36mPipeline.__call__\u001b[0;34m(self, inputs, num_workers, batch_size, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1112\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mnext\u001b[39m(\n\u001b[1;32m   1113\u001b[0m         \u001b[39miter\u001b[39m(\n\u001b[1;32m   1114\u001b[0m             \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_iterator(\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1117\u001b[0m         )\n\u001b[1;32m   1118\u001b[0m     )\n\u001b[1;32m   1119\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1120\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrun_single(inputs, preprocess_params, forward_params, postprocess_params)\n",
      "File \u001b[0;32m~/Documents/GitHub/ai-tools/.venv/lib/python3.11/site-packages/transformers/pipelines/base.py:1127\u001b[0m, in \u001b[0;36mPipeline.run_single\u001b[0;34m(self, inputs, preprocess_params, forward_params, postprocess_params)\u001b[0m\n\u001b[1;32m   1125\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mrun_single\u001b[39m(\u001b[39mself\u001b[39m, inputs, preprocess_params, forward_params, postprocess_params):\n\u001b[1;32m   1126\u001b[0m     model_inputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpreprocess(inputs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mpreprocess_params)\n\u001b[0;32m-> 1127\u001b[0m     model_outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mforward(model_inputs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mforward_params)\n\u001b[1;32m   1128\u001b[0m     outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpostprocess(model_outputs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mpostprocess_params)\n\u001b[1;32m   1129\u001b[0m     \u001b[39mreturn\u001b[39;00m outputs\n",
      "File \u001b[0;32m~/Documents/GitHub/ai-tools/.venv/lib/python3.11/site-packages/transformers/pipelines/base.py:1026\u001b[0m, in \u001b[0;36mPipeline.forward\u001b[0;34m(self, model_inputs, **forward_params)\u001b[0m\n\u001b[1;32m   1024\u001b[0m     \u001b[39mwith\u001b[39;00m inference_context():\n\u001b[1;32m   1025\u001b[0m         model_inputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_ensure_tensor_on_device(model_inputs, device\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdevice)\n\u001b[0;32m-> 1026\u001b[0m         model_outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_forward(model_inputs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mforward_params)\n\u001b[1;32m   1027\u001b[0m         model_outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_ensure_tensor_on_device(model_outputs, device\u001b[39m=\u001b[39mtorch\u001b[39m.\u001b[39mdevice(\u001b[39m\"\u001b[39m\u001b[39mcpu\u001b[39m\u001b[39m\"\u001b[39m))\n\u001b[1;32m   1028\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/Documents/GitHub/ai-tools/.venv/lib/python3.11/site-packages/transformers/pipelines/text2text_generation.py:187\u001b[0m, in \u001b[0;36mText2TextGenerationPipeline._forward\u001b[0;34m(self, model_inputs, **generate_kwargs)\u001b[0m\n\u001b[1;32m    185\u001b[0m generate_kwargs[\u001b[39m\"\u001b[39m\u001b[39mmax_length\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m generate_kwargs\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mmax_length\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel\u001b[39m.\u001b[39mconfig\u001b[39m.\u001b[39mmax_length)\n\u001b[1;32m    186\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcheck_inputs(input_length, generate_kwargs[\u001b[39m\"\u001b[39m\u001b[39mmin_length\u001b[39m\u001b[39m\"\u001b[39m], generate_kwargs[\u001b[39m\"\u001b[39m\u001b[39mmax_length\u001b[39m\u001b[39m\"\u001b[39m])\n\u001b[0;32m--> 187\u001b[0m output_ids \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodel\u001b[39m.\u001b[39;49mgenerate(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mmodel_inputs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mgenerate_kwargs)\n\u001b[1;32m    188\u001b[0m out_b \u001b[39m=\u001b[39m output_ids\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m]\n\u001b[1;32m    189\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mframework \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mpt\u001b[39m\u001b[39m\"\u001b[39m:\n",
      "File \u001b[0;32m~/Documents/GitHub/ai-tools/.venv/lib/python3.11/site-packages/torch/utils/_contextlib.py:115\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[39m@functools\u001b[39m\u001b[39m.\u001b[39mwraps(func)\n\u001b[1;32m    113\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdecorate_context\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m    114\u001b[0m     \u001b[39mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 115\u001b[0m         \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/Documents/GitHub/ai-tools/.venv/lib/python3.11/site-packages/transformers/generation/utils.py:1329\u001b[0m, in \u001b[0;36mGenerationMixin.generate\u001b[0;34m(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, assistant_model, streamer, **kwargs)\u001b[0m\n\u001b[1;32m   1321\u001b[0m         logger\u001b[39m.\u001b[39mwarning(\n\u001b[1;32m   1322\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mA decoder-only architecture is being used, but right-padding was detected! For correct \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1323\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mgeneration results, please set `padding_side=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mleft\u001b[39m\u001b[39m'\u001b[39m\u001b[39m` when initializing the tokenizer.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1324\u001b[0m         )\n\u001b[1;32m   1326\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig\u001b[39m.\u001b[39mis_encoder_decoder \u001b[39mand\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mencoder_outputs\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m model_kwargs:\n\u001b[1;32m   1327\u001b[0m     \u001b[39m# if model is encoder decoder encoder_outputs are created\u001b[39;00m\n\u001b[1;32m   1328\u001b[0m     \u001b[39m# and added to `model_kwargs`\u001b[39;00m\n\u001b[0;32m-> 1329\u001b[0m     model_kwargs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_prepare_encoder_decoder_kwargs_for_generation(\n\u001b[1;32m   1330\u001b[0m         inputs_tensor, model_kwargs, model_input_name\n\u001b[1;32m   1331\u001b[0m     )\n\u001b[1;32m   1333\u001b[0m \u001b[39m# 5. Prepare `input_ids` which will be used for auto-regressive generation\u001b[39;00m\n\u001b[1;32m   1334\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig\u001b[39m.\u001b[39mis_encoder_decoder:\n",
      "File \u001b[0;32m~/Documents/GitHub/ai-tools/.venv/lib/python3.11/site-packages/transformers/generation/utils.py:642\u001b[0m, in \u001b[0;36mGenerationMixin._prepare_encoder_decoder_kwargs_for_generation\u001b[0;34m(self, inputs_tensor, model_kwargs, model_input_name)\u001b[0m\n\u001b[1;32m    640\u001b[0m encoder_kwargs[\u001b[39m\"\u001b[39m\u001b[39mreturn_dict\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m    641\u001b[0m encoder_kwargs[model_input_name] \u001b[39m=\u001b[39m inputs_tensor\n\u001b[0;32m--> 642\u001b[0m model_kwargs[\u001b[39m\"\u001b[39m\u001b[39mencoder_outputs\u001b[39m\u001b[39m\"\u001b[39m]: ModelOutput \u001b[39m=\u001b[39m encoder(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mencoder_kwargs)\n\u001b[1;32m    644\u001b[0m \u001b[39mreturn\u001b[39;00m model_kwargs\n",
      "File \u001b[0;32m~/Documents/GitHub/ai-tools/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/Documents/GitHub/ai-tools/.venv/lib/python3.11/site-packages/transformers/models/bart/modeling_bart.py:813\u001b[0m, in \u001b[0;36mBartEncoder.forward\u001b[0;34m(self, input_ids, attention_mask, head_mask, inputs_embeds, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    810\u001b[0m \u001b[39mif\u001b[39;00m inputs_embeds \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    811\u001b[0m     inputs_embeds \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39membed_tokens(input_ids) \u001b[39m*\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39membed_scale\n\u001b[0;32m--> 813\u001b[0m embed_pos \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49membed_positions(\u001b[39minput\u001b[39;49m)\n\u001b[1;32m    814\u001b[0m embed_pos \u001b[39m=\u001b[39m embed_pos\u001b[39m.\u001b[39mto(inputs_embeds\u001b[39m.\u001b[39mdevice)\n\u001b[1;32m    816\u001b[0m hidden_states \u001b[39m=\u001b[39m inputs_embeds \u001b[39m+\u001b[39m embed_pos\n",
      "File \u001b[0;32m~/Documents/GitHub/ai-tools/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/Documents/GitHub/ai-tools/.venv/lib/python3.11/site-packages/transformers/models/bart/modeling_bart.py:140\u001b[0m, in \u001b[0;36mBartLearnedPositionalEmbedding.forward\u001b[0;34m(self, input_ids, past_key_values_length)\u001b[0m\n\u001b[1;32m    135\u001b[0m bsz, seq_len \u001b[39m=\u001b[39m input_ids\u001b[39m.\u001b[39mshape[:\u001b[39m2\u001b[39m]\n\u001b[1;32m    136\u001b[0m positions \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39marange(\n\u001b[1;32m    137\u001b[0m     past_key_values_length, past_key_values_length \u001b[39m+\u001b[39m seq_len, dtype\u001b[39m=\u001b[39mtorch\u001b[39m.\u001b[39mlong, device\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mweight\u001b[39m.\u001b[39mdevice\n\u001b[1;32m    138\u001b[0m )\u001b[39m.\u001b[39mexpand(bsz, \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[0;32m--> 140\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mforward(positions \u001b[39m+\u001b[39;49m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moffset)\n",
      "File \u001b[0;32m~/Documents/GitHub/ai-tools/.venv/lib/python3.11/site-packages/torch/nn/modules/sparse.py:162\u001b[0m, in \u001b[0;36mEmbedding.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    161\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[0;32m--> 162\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49membedding(\n\u001b[1;32m    163\u001b[0m         \u001b[39minput\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpadding_idx, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmax_norm,\n\u001b[1;32m    164\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mnorm_type, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mscale_grad_by_freq, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msparse)\n",
      "File \u001b[0;32m~/Documents/GitHub/ai-tools/.venv/lib/python3.11/site-packages/torch/nn/functional.py:2210\u001b[0m, in \u001b[0;36membedding\u001b[0;34m(input, weight, padding_idx, max_norm, norm_type, scale_grad_by_freq, sparse)\u001b[0m\n\u001b[1;32m   2204\u001b[0m     \u001b[39m# Note [embedding_renorm set_grad_enabled]\u001b[39;00m\n\u001b[1;32m   2205\u001b[0m     \u001b[39m# XXX: equivalent to\u001b[39;00m\n\u001b[1;32m   2206\u001b[0m     \u001b[39m# with torch.no_grad():\u001b[39;00m\n\u001b[1;32m   2207\u001b[0m     \u001b[39m#   torch.embedding_renorm_\u001b[39;00m\n\u001b[1;32m   2208\u001b[0m     \u001b[39m# remove once script supports set_grad_enabled\u001b[39;00m\n\u001b[1;32m   2209\u001b[0m     _no_grad_embedding_renorm_(weight, \u001b[39minput\u001b[39m, max_norm, norm_type)\n\u001b[0;32m-> 2210\u001b[0m \u001b[39mreturn\u001b[39;00m torch\u001b[39m.\u001b[39;49membedding(weight, \u001b[39minput\u001b[39;49m, padding_idx, scale_grad_by_freq, sparse)\n",
      "\u001b[0;31mIndexError\u001b[0m: index out of range in self"
     ]
    }
   ],
   "source": [
    "ARTICLE = \"\"\"\n",
    "Microsoft FY23 Fourth Quarter Earnings Conference Call\n",
    "Brett Iversen, Satya Nadella, Amy Hood\n",
    "Tuesday, July 25, 2023\n",
    "\n",
    "BRETT IVERSEN: Good afternoon and thank you for joining us today. On the call with me are Satya Nadella, chairman and chief executive officer, Amy Hood, chief financial officer, Alice Jolla, chief accounting officer, and Keith Dolliver, deputy general counsel.\n",
    "On the Microsoft Investor Relations website, you can find our earnings press release and financial summary slide deck, which is intended to supplement our prepared remarks during today’s call and provides the reconciliation of differences between GAAP and non-GAAP financial measures. More detailed outlook slides will be available on the Microsoft Investor Relations website when we provide outlook commentary on today’s call.\n",
    "On this call we will discuss certain non-GAAP items. The non-GAAP financial measures provided should not be considered as a substitute for or superior to the measures of financial performance prepared in accordance with GAAP. They are included as additional clarifying items to aid investors in further understanding the company's fourth quarter performance in addition to the impact these items and events have on the financial results. \n",
    "All growth comparisons we make on the call today relate to the corresponding period of last year unless otherwise noted. We will also provide growth rates in constant currency, when available, as a framework for assessing how our underlying businesses performed, excluding the effect of foreign currency rate fluctuations. Where growth rates are the same in constant currency, we will refer to the growth rate only. \n",
    "We will post our prepared remarks to our website immediately following the call until the complete transcript is available. Today's call is being webcast live and recorded. If you ask a question, it will be included in our live transmission, in the transcript, and in any future use of the recording. You can replay the call and view the transcript on the Microsoft Investor Relations website. \n",
    "During this call, we will be making forward-looking statements which are predictions, projections, or other statements about future events. These statements are based on current expectations and assumptions that are subject to risks and uncertainties. Actual results could materially differ because of factors discussed in today's earnings press release, in the comments made during this conference call, and in the risk factor section of our Form 10-K, Forms 10-Q, and other reports and filings with the Securities and Exchange Commission. We do not undertake any duty to update any forward-looking statement. \n",
    "And with that, I’ll turn the call over to Satya. \n",
    "\n",
    "SATYA NADELLA: Thank you very much, Brett.\n",
    "We had a solid close to our fiscal year. \n",
    "The Microsoft Cloud surpassed $110 billion in annual revenue, up 27% in constant currency, with Azure all-up accounting for more than 50% of the total for the first time.\n",
    "Every customer I speak with is asking not only how, but how fast, they can apply next generation AI to address the biggest opportunities and challenges they face – and to do so safely and responsibly.\n",
    "To that end, we remain focused on three key priorities: \n",
    "First, helping customers use the breadth and depth of Microsoft Cloud to get the most value out of their spend.\n",
    "Second, investing to lead in the new AI platform shift by infusing AI across every layer of the tech stack.\n",
    "And, third, driving operating leverage.\n",
    "Now, I’ll highlight examples of our progress, starting with infrastructure.\n",
    "Azure continues to take share, as customers migrate their existing workloads and invest in new ones.\n",
    "We continue to see more cloud migrations, as it remains early when it comes to long-term cloud opportunity.\n",
    "We are also seeing increasing momentum with Azure Arc, which now has 18,000 customers, up 150% year-over-year, including Carnival Corp., Domino’s, Thermo Fisher.\n",
    "And Azure AI is ushering in new, born-in-the cloud AI-first workloads, with the best selection of frontier and open models, including Meta’s recent announcement supporting Llama on Azure and Windows, as well as OpenAI.\n",
    "We have great momentum across Azure OpenAI Service.\n",
    "More than 11,000 organizations across industries, including Ikea, Volvo Group, Zurich Insurance, as well as digital natives like Flipkart, Humane, Kahoot, Miro, Typeface, use the service.\n",
    "That’s nearly 100 new customers added every day this quarter.\n",
    "Mercedes-Benz, for example, is bringing ChatGPT via Azure OpenAI to more than 900,000 vehicles in the United States, making its in-car voice assistant more intuitive. And Moody’s built its own internal copilot to improve productivity of its 14,000 employees.\n",
    "We are also partnering broadly to scale this next generation of AI to more customers. \n",
    "Snowflake, for example, will increase its Azure spend as it builds new integrations with Azure OpenAI. And, KPMG has announced a multi-billion-dollar commitment to our cloud and AI services to transform professional services.\n",
    "Now, on to data. \n",
    "Every AI app starts with data, and having a comprehensive data and analytics platform is more important than ever.\n",
    "Our Intelligent Data Platform brings together operational databases, analytics, and governance so organizations can spend more time creating value and less time integrating their data estate.\n",
    "We introduced Microsoft Fabric this quarter, which unifies compute, storage, and governance, with a disruptive business model.\n",
    "One month in, we are encouraged by early interest and usage. Over 8,000 customers have signed up to trial the service and are actively using it. And over 50% are using four or more workloads.\n",
    "All-up, we once again took share with our analytics solutions, with customers like Bridgestone, Chevron, and Equinor turning to our stack.\n",
    "Now, on to developers.\n",
    "New Azure AI Studio is becoming the tool of choice for AI development in this new era, helping organizations ground, fine-tune, evaluate, and deploy models – and do so responsibly. \n",
    "VS Code and GitHub Copilot are category-leading products when it comes to how developers code every day.\n",
    "Nearly 90% of GitHub Copilot sign-ups are self-service, indicating strong organic interest and pull through. \n",
    "More than 27,000 organizations – up 2X quarter-over-quarter – have chosen GitHub Copilot for Business to increase the productivity of their developers, including Airbnb, Dell, and Scandinavian Airlines. \n",
    "We’re also applying AI across low-code/no-code toolchain to help domain experts automate workflows, create apps and web pages, build virtual agents, or analyze data, using just natural language.  \n",
    "Copilot in Power BI combines the power of large language models with an organization’s data to generate insights faster. And Copilot in Power Pages makes it easier to create secure, low-code business websites.\n",
    "One of our tools that has really taken off is Copilot in Power Virtual Agents, which is delivering one of the biggest benefits of this new era of AI: helping customer service agents be significantly more productive.\n",
    "HP and Virgin Money, for example, have both built custom chatbots with Copilot in Power Virtual Agents that were trained to answer complex customer inquiries.\n",
    "All-up, more than 63,000 organizations have used AI-powered capabilities in Power Platform, up 75% quarter-over-quarter.\n",
    "Finally, Power Automate now has 10 million monthly active users at companies like Jaguar Land Rover, Repsol, Rolls-Royce, up 55% year-over-year. \n",
    "And we’re going further with new process mining capabilities in Power Automate, which are helping organizations optimize business processes – and in turn build their AI advantage. \n",
    "Now, on to business applications.\n",
    "We are taking share in every category, as we help organizations across the private and public sector – from Avis, to Albertsons Companies, to Breville, to Equinox, and the U.S. Department of Veterans Affairs – transform their mission-critical business processes.\n",
    "All-up, Dynamics surpassed $5 billion in revenue over the past fiscal year, with our customer experience, service, and finance & supply chain businesses all surpassing $1 billion in annual sales.\n",
    "This quarter, we brought Dynamics 365 Copilot to our ERP portfolio, including finance, project operations, and supply management.\n",
    "And with our new Microsoft Sales Copilot sellers can ground their customer interactions with data from CRM systems – including both Salesforce and Dynamics – to personalize customer interactions and close more deals.\n",
    "Now, on to our industry and cross-industry clouds.\n",
    "Our Microsoft Cloud for Sustainability is helping customers like Costco, Land O’Lakes, and REI take action to meet their environmental goals. \n",
    "And, in healthcare, hundreds of organizations are using our Nuance DAX ambient intelligence solution to automatically document patient encounters at the point of care.\n",
    "This quarter, we expanded our collaboration with Epic to integrate Nuance DAX Express directly into their industry leading EHR system.\n",
    "Now, on to future of work.\n",
    "Across industries, customers like Ahold Delhaize, Deutsche Bank, Novartis, Siemens, Wells Fargo are choosing Microsoft 365 premium offerings for differentiated security, compliance, voice, and analytics value. \n",
    "And four months ago, we introduced a new pillar of customer value with Microsoft 365 Copilot.\n",
    "We are now rolling out Microsoft 365 Copilot to 600 paid customers through our early access program, and feedback from organizations like Emirates NBD, General Motors, Goodyear, and Lumen is that it’s a game changer for employee productivity.\n",
    "We continue to build momentum in Microsoft Teams across collaboration, chat, meetings, and calling.\n",
    "We now have more than 1,900 apps in Teams app store. And companies in every industry, from British Airways, to Dentsu, to Eli Lilly and Manulife, have built over 145,000 custom line of business apps, bringing business process directly into the flow of work.\n",
    "Five months in, Teams Premium has already surpassed 600,000 seats, as companies like BNY Mellon, Clifford Chance, PepsiCo, and Starbucks, chose the add-on for advanced features like end-to-end encryption and real-time translation.\n",
    "Teams Phone is the market leader in cloud calling, with more than 17 million PSTN users, up 45% year-over-year.\n",
    "Teams Rooms is used by more than 70% of the Fortune 500 – including L’Oreal, United Airlines, and US Bank. And revenue more than doubled year-over-year this quarter.\n",
    "\n",
    "And with Microsoft Viva, we are creating a new market category for employee experience. Viva now has 35 million monthly active users, as companies like CBRE, Fujitsu, and Unisys turn to the platform to build data-driven, high-performance organizations. \n",
    "Now, on to Windows.\n",
    "The number of devices running Windows 11 has more than doubled in the last year, and we are seeing continued growth in Windows 11 commercial deployments worldwide by companies like AT&T, Krones, and Westpac.\n",
    "We are also transforming how Windows is experienced and managed for enterprise customers with Azure Virtual Desktop and Windows 365, which together surpassed $1 billion in revenue for the first time over the past 12 months.\n",
    "Enbridge, Eurowings, Marriott International, and TD Bank Group, for example, all chose cloud-delivered Windows this quarter.\n",
    "Windows 11 is also rapidly becoming a powerful new canvas in this new era of AI.\n",
    "We introduced Windows Copilot this quarter, helping every Windows 11 user become a power user with just natural language, and are excited to put it in the hands of more people in the coming months.\n",
    "Now, on to Security.\n",
    "More than one million organizations now count on our comprehensive, AI-powered solutions to protect their digital estate across clouds and endpoint platforms, up 26% year-over-year. \n",
    "More than 60% – including leading enterprises like ABN AMRO, Dow, and HEINEKEN – use 4 or more of our security products, up 33% year-over-year, underscoring our end-to-end differentiation.\n",
    "And we once again took share across all major categories we serve, as we innovate to protect customers.\n",
    "In identity, Microsoft Entra ID has more than 610 million monthly active users.\n",
    "And we are adding SSE to our Entra product family to complement our leading identity solution, and secure access to any app or resource, from anywhere. \n",
    "Finally, our Security Copilot – the first product to apply this next generation of AI to SecOps – will be available to customers via a paid early access program this fall.  \n",
    "Now, on to LinkedIn.\n",
    "LinkedIn’s revenue surpassed $15 billion for the first time this fiscal year and membership growth has now accelerated for eight quarters in a row, a testament to how mission critical the platform has become to help more than 950 million members connect, learn, sell, and get hired.\n",
    "Our Talent Solutions business surpassed $7 billion in revenue for the first time over the past 12 months, and our hiring business took share for the fourth consecutive quarter.\n",
    "We continue to use AI to help our members and customers connect to opportunities and tap into experiences of experts on the platform. Our AI-powered collaborative articles are now the fastest-growing traffic driver to LinkedIn.\n",
    "And finally, we’re helping LinkedIn stay trusted and authentic. More than 7 million members have verified who they are or where they work, many using new integrations with Microsoft Entra, as well as CLEAR and Hyperverge.\n",
    "Now, on to search, advertising, and news.\n",
    "While it’s early in our journey, we are reshaping daily search and web habits with our Copilot for the web.\n",
    "This quarter, we introduced new AI-powered features, including multimodal capabilities with visual search in Bing Chat. \n",
    "We’re expanding to businesses, with Bing Chat Enterprise, which offers commercial data protection, providing an easy on-ramp for any organization looking to get the benefit of this next generation of AI today. \n",
    "Bing is also the default search experience for OpenAI’s ChatGPT, bringing timelier answers with links to reputable sources to ChatGPT users. \n",
    "To date, Bing users have engaged in more than one billion chats and created more than 750 million images with Bing Image Creator. And Microsoft Edge took share for the ninth consecutive quarter. \n",
    "More broadly, we’re growing our ad network, which is now available in 187 markets, spanning search, display, native, retail media, video, and connected TV. \n",
    "Now, on to gaming.\n",
    "Last week we extended our Activision Blizzard merger agreement deadline to October. We continue to work through the regulatory approval process and remain confident about getting the deal done. \n",
    "We are committed to bringing more games to more players everywhere.\n",
    "Great content is key to our approach, and our pipeline has never been stronger. \n",
    "We announced our most ambitious line up of games ever at our showcase last month, including 21 titles that will be available via Xbox Game Pass. \n",
    "And we’re looking forward to the release of Starfield this fall, Bethesda’s first new universe in 25 years.\n",
    "All-up, we set new fourth quarter highs for monthly active users, driven by strength off-console, as well as monthly active devices. And we saw record fourth quarter engagement across Game Pass, with hours played up 22% year-over-year.  \n",
    "And just last week, we announced Game Pass Core, bringing together online play from Xbox Live and content from Game Pass into a single offering.\n",
    "In closing, I am energized about the opportunities ahead.\n",
    "We continue to innovate across the tech stack to help our customers thrive in the new era of AI.\n",
    "And with that, let me turn it over to Amy.\n",
    "AMY HOOD: Thank you, Satya, and good afternoon everyone. This quarter, revenue was $56.2 billion, up 8% and 10% in constant currency. Earnings per share was $2.69 and increased 21% and 23% in constant currency.\n",
    "In our largest quarter of the year, results exceeded expectations with focused execution by our sales and partner teams. These execution efforts led to share gains again this quarter in Azure, Dynamics, Security, and Edge.\n",
    "In our commercial business, we continued to see healthy renewal strength which includes our upsell and attach motions, particularly with Microsoft 365 E5. Growth of new business continued to be moderated for products sold outside the Microsoft 365 suite including standalone Office 365, EMS, and Windows Commercial products. As expected in Azure, we saw a continuation of the optimization and new workload trends from the prior quarter.\n",
    "In our consumer business, the PC market overall was in line with expectations although the early timing of back-to-school inventory builds benefitted Windows OEM. Advertising spend was slightly lower than anticipated which impacted Search and news advertising and LinkedIn Marketing Solutions. \n",
    "Commercial bookings decreased 2% and 1% in constant currency, in line with expectations, against a prior year comparable that was our largest commercial bookings quarter ever. In addition to the healthy execution across our renewal sales motions mentioned earlier, we saw a record number of 10-million-dollar-plus contracts for both Azure and Microsoft 365. And, the average annualized value for our large, long-term Azure contracts was the highest it’s ever been, driven by customer demand for our innovative cloud solutions today as well as the interest in AI opportunities ahead.\n",
    "Commercial remaining performance obligation increased 19% and 18% in constant currency to $224 billion. Roughly 45% will be recognized in revenue in the next 12 months, up 13% year-over-year. The remaining portion, which will be recognized beyond the next 12 months, increased 22%. And this quarter, our annuity mix increased to 97%.\n",
    "FX impact on total company revenue, segment level revenue, and operating expense growth was as expected. FX decreased COGS growth by 1 point, 1 point favorable to expectations.\n",
    "Microsoft Cloud revenue was $30.3 billion and grew 21% and 23% in constant currency, slightly ahead of expectations. \n",
    "Microsoft Cloud gross margin percentage increased roughly 3 points year-over-year to 72%, also slightly ahead of expectations. Excluding the impact of the change in accounting estimate for useful lives, Microsoft Cloud gross margin percentage increased slightly driven by improvements in Office 365, partially offset by lower Azure margin and the impact of scaling our AI infrastructure to meet growing demand.\n",
    "Company gross margin dollars increased 11% and 13% in constant currency, including 2 points due to the change in accounting estimate. Gross margin percentage increased year-over-year to 70%. Excluding the impact of the change in accounting estimate, gross margin percentage increased slightly driven by improvements in Office 365.\n",
    "Operating expense increased 2%, in line with expectations, as savings across the company from our focus on prioritization and efficiency were offset by the charge related to the Irish Data Protection Commission matter. At a total company level, headcount at the end of June was flat compared to a year ago. \n",
    "Operating income increased 18% and 21% in constant currency, including 4 points due to the change in accounting estimate. Operating margins increased roughly 4 points year-over-year to 43%. Excluding the impact of the change in accounting estimate, operating margins increased roughly 2 points driven by improved operating leverage through disciplined cost management.\n",
    "Now to our segment results.\n",
    "Revenue from Productivity and Business Processes was $18.3 billion and grew 10% and 12% in constant currency, ahead of expectations with better-than-expected results in Office Commercial, partially offset by LinkedIn.\n",
    "Office commercial revenue grew 12% and 14% in constant currency. Office 365 commercial revenue increased 15% and 17% in constant currency, a bit better than expected with particular strength in E5 upsell at renewal noted earlier. Paid Office 365 commercial seats grew 11% year-over-year with installed base expansion across all workloads and customer segments. Seat growth was again driven by our small and medium business and frontline worker offerings.\n",
    "Office commercial licensing declined 20% and 18% in constant currency with better-than-expected transactional purchasing.\n",
    "Office consumer revenue increased 3% and 6% in constant currency with continued momentum in Microsoft 365 subscriptions, which grew 12% to 67 million. \n",
    "LinkedIn revenue increased 5% and 7% in constant currency, driven by growth in Talent Solutions with some continued bookings impact from the weaker hiring environment in key verticals. Growth was partially offset by a decline in Marketing Solutions due to the lower ad spend noted earlier. \n",
    "Dynamics revenue grew 19% and 21% in constant currency driven by Dynamics 365, which grew 26% and 28% in constant currency with continued healthy growth across all workloads. \n",
    "Segment gross margin dollars increased 14% and 16% in constant currency and gross margin percentage increased roughly 3 points year-over-year. Excluding the impact of the change in accounting estimate, gross margin percentage increased roughly 1 point driven by improvements in Office 365. Operating expenses decreased slightly, and operating income increased 25% and 29% in constant currency, including 3 points due to the change in accounting estimate. \n",
    "Next, the Intelligent Cloud segment. Revenue was $24 billion, increasing 15% and 17% in constant currency, slightly ahead of expectations. \n",
    "Overall, server products and cloud services revenue increased 17% and 18% in constant currency. Azure and other cloud services revenue grew 26% and 27% in constant currency, including roughly 1 point from AI services, as expected.\n",
    "In our per-user business, the enterprise mobility and security installed base grew 11% to over 256 million seats with impact from the continued growth trends in new business noted earlier. \n",
    "In our on-premises server business, revenue decreased 1% and was relatively unchanged in constant currency, driven by a slight decrease in new annuity contracts which carry higher in-period revenue recognition.\n",
    "Enterprise Services revenue grew 4% and 5% in constant currency, with better-than-expected performance across Enterprise Support Services and Industry Solutions.\n",
    "Segment gross margin dollars increased 16% and 17% in constant currency and gross margin percentage increased slightly. Excluding the impact of the change in accounting estimate, gross margin percentage declined roughly 2 points driven by sales mix shift to Azure and the lower Azure margin noted earlier. Operating expenses increased 10%. Operating income grew 20% and 22% in constant currency, with roughly 6 points from the change in accounting estimate.\n",
    "Now to More Personal Computing. Revenue was $13.9 billion, decreasing 4% and 3% in constant currency, above expectations driven by better-than-expected performance in Windows partially offset by Gaming. \n",
    "Windows OEM revenue decreased 12% year-over-year, ahead of expectations due to 7 points of benefit from early back-to-school inventory builds, while the overall PC market was as expected.\n",
    "Devices revenue decreased 20% and 18% in constant currency, roughly in line with expectations. \n",
    "Windows commercial products and cloud services revenue increased 2% and 3% in constant currency, ahead of expectations due to the renewal strength noted earlier even with the moderated growth of new business in standalone offerings.\n",
    "Search and news advertising revenue ex-TAC increased 8%, a bit behind expectations due to lower ad spend noted earlier. Higher search volumes, share gains again this quarter for our Edge browser, and the benefit from the Xandr acquisition were partially offset by the impact from third party partnerships. \n",
    "And in Gaming, revenue increased 1% and 2% in constant currency, lower than expected due to weakness in first-party and third-party content performance. Xbox content and services revenue increased 5% and 6% in constant currency and Xbox hardware revenue declined 13%.\n",
    "Segment gross margin dollars declined 2% and were relatively unchanged in constant currency and gross margin percentage increased roughly 1 point year-over-year driven by sales mix shift to higher margin businesses. Operating expenses declined 9% and 8% in constant currency. Operating income increased 4% and 6% in constant currency.\n",
    "Now back to total company results.\n",
    "Capital expenditures including finance leases were $10.7 billion to support cloud demand, including investments in AI infrastructure. Cash paid for P, P, and E was $8.9 billion.\n",
    "Cash flow from operations was $28.8 billion, up 17% year-over-year as strong cloud billings and collections were partially offset by a tax payment related to the R&D capitalization provision. Free cash flow was $19.8 billion, up 12% year-over-year. Excluding the impact of this tax payment, cash flow from operations increased 22% and free cash flow increased 19%.\n",
    "This quarter, other income and expense was $473 million, higher than anticipated driven by net gains on foreign currency remeasurement. \n",
    "Our effective tax rate was approximately 19%.\n",
    "And finally, we returned $9.7 billion to shareholders through share repurchases and dividends, bringing our total cash returned to shareholders to over $38 billion for the full fiscal year.\n",
    "Now, let’s turn to next fiscal year and start with a few reminders. \n",
    "First, the change in accounting estimate for the useful life of server and network equipment resulted in $3.7 billion of depreciation expense shifting from FY23 to future periods. Our FY23 operating income and margins benefited from this change in accounting estimate and that will be a headwind to growth in FY24 as the benefit reduces to $2.1 billion.\n",
    "Next, my outlook commentary, for both the full year and next quarter, is on a US dollar basis unless specifically noted otherwise. \n",
    "And, my outlook does not include any impact from the Activision acquisition, which we continue to work towards closing, subject to obtaining required regulatory approvals. \n",
    "Now for some thoughts on the full year of FY24.\n",
    "With the weaker US dollar and assuming current rates remain stable, we expect FX to increase full year revenue growth by approximately 1 point with no impact to COGS or operating expense growth. The impact in H1 is expected to be greater than H2.\n",
    "At a total company level, revenue growth from our commercial business will continue to be driven by the Microsoft Cloud and will again outpace the growth from our consumer business. Even with strong demand and a leadership position, growth from our AI services will be gradual as Azure AI scales and our copilots reach general availability dates. So, for FY24, the impact will be weighted towards H2. \n",
    "To support our Microsoft Cloud growth and demand for our AI platform, we will accelerate investment in our cloud infrastructure. We expect capital expenditures to increase sequentially each quarter through the year as we scale to meet demand signals. \n",
    "We are committed to driving operating leverage and therefore we will manage our total cost growth across COGS and operating expense in line with the demand signals we see as well as revenue growth. Increased capital spend will drive higher COGS growth than in FY23, and FY24 operating expense growth will remain low as we prioritize our spend. Therefore, we expect full year operating margins to remain flat year-over-year, even with the headwind from the change in accounting estimate.\n",
    "And finally, we expect our FY24 tax rate to be around 19%.\n",
    "Now, to the outlook for the first quarter.\n",
    "First, FX. Based on current rates, we expect FX to increase total revenue and operating expense growth by approximately 1 point with no impact to COGS growth. Within the segments, we expect FX to increase revenue growth in Intelligent Cloud by 1 point with no impact to Productivity and Business Processes or More Personal Computing.\n",
    "In commercial bookings, strong execution across our core annuity sales motions, including our renewal and upsell motions, along with long term Azure commitments should drive healthy growth on a growing expiry base. \n",
    "Microsoft Cloud gross margin percentage should decrease roughly 1 point year-over-year driven by the accounting estimate change headwind noted earlier. Excluding that impact, Q1 cloud gross margin percentage will be up roughly 1 point primarily driven by improvements in Azure and Office 365, partially offset by sales mix shift to Azure and the impact of scaling our AI infrastructure to meet growing demand.\n",
    "We expect capital expenditures to increase sequentially on a dollar basis, as noted earlier, driven by investments in our AI infrastructure. Reminder there can be normal quarterly spend variability in the timing of our cloud infrastructure buildout. \n",
    "Next to segment guidance. \n",
    "In Productivity and Business Processes, we expect revenue to grow between 9 and 11% or $18 to $18.3 billion US dollars.\n",
    "In Office Commercial, revenue growth will again be driven by Office 365 with seat growth across customer segments and ARPU growth thru E5. We expect Office 365 revenue growth to be roughly 16% in constant currency. In our on-premises business, we expect revenue to decline in the low 20s. \n",
    "In Office consumer, we expect revenue growth in the low to mid-single digits, driven by Microsoft 365 subscriptions.\n",
    "For LinkedIn, we expect revenue growth in the low to mid-single digits. Even with share gains in our hiring business, growth will continue to be impacted by the overall markets for recruiting and advertising, especially in the technology industry where we have significant exposure. \n",
    "And in Dynamics, we expect revenue growth in the mid to high-teens driven by continued growth in Dynamics 365.\n",
    "For Intelligent Cloud we expect revenue to grow between 15 and 16%, or 14 and 15% in constant currency. Revenue should be $23.3 to $23.6 billion US dollars.\n",
    "Revenue will continue to be driven by Azure which, as a reminder, can have quarterly variability primarily from our per-user business and from in-period revenue recognition depending on the mix of contracts. \n",
    "In Azure, we expect revenue growth to be 25 to 26% in constant currency, including roughly 2 points from all Azure AI services. Growth continues to be driven by our Azure consumption business and we expect the trends from Q4 to continue into Q1. Our per-user business should continue to benefit from Microsoft 365 suite momentum, though we expect continued moderation in growth rates given the size of the installed base. \n",
    "In our on-premises server business, we expect revenue to decline low to mid-single digits against a prior year comparable that benefited from annuity purchasing ahead of the SQL Server 2022 launch.\n",
    "And in Enterprise Services, revenue should decline low to mid-single digits year-over-year as growth in Enterprise Support Services will be more than offset by a decline in Industry Solutions. \n",
    "In More Personal Computing, we expect revenue of $12.5 to $12.9 billion US dollars. \n",
    "Windows OEM revenue should decline low to mid-teens, including 5 points of negative impact from the earlier back-to-school inventory builds that were pulled into the fourth quarter. Our guide assumes no significant changes to the PC demand environment.\n",
    "In Devices, revenue should decline in the mid-30s due to the overall PC market and adjustments we made in our portfolio with an increased focus on our higher margin premium products.  \n",
    "In Windows commercial products and cloud services, customer demand for Microsoft 365 and our advanced security solutions should drive revenue growth in the mid to high-single digits.\n",
    "Search and news advertising ex-TAC revenue growth should be mid to high-single digits, roughly 5 points higher than overall Search and news advertising revenue, driven by continued volume strength supported by Edge browser share gains. Growth will continue to be impacted by the advertising spend environment and third-party partnerships mentioned earlier. We continue to be excited by Bing usage signals and the longer term opportunity as we invest in AI.\n",
    "And in Gaming, we expect revenue growth in the mid-single digits. We expect Xbox content and services revenue growth in the mid to high-single digits driven by first-party and third-party content as well as Xbox Game Pass. \n",
    "Now back to company guidance.\n",
    "We expect COGS between $16.6 to $16.8 billion US dollars and operating expense of $13.5 to $13.6 billion US dollars. Together, total cost growth should be around 6%. \n",
    "Other income and expense should be roughly $300 million as interest income is expected to more than offset interest expense. Two reminders, this does not include any impact from Activision on interest income and expense and we are required to recognize mark-to-market gains or losses on our equity portfolio, which can increase quarterly volatility.\n",
    "We expect our Q1 effective tax rate to be around 19%. \n",
    "And finally, as a reminder for Q1 cash flow, we expect to make a $2.7 billion cash tax payment related to the TCJA transition tax. We do not expect a payment related to the R&D capitalization provision in Q1. \n",
    "In closing, as a company, we delivered on the FY23 financial commitments we discussed a year ago on revenue and operating margin. A focus on operational excellence allowed us to achieve these targets while we delivered near term value to customers and prioritized our investments to continue to lead in the future. As we start FY24, we are excited for the opportunities ahead, and remain focused on delivering the three key priorities Satya mentioned. We’ll maintain our lead as the top commercial cloud by helping customers use the breadth and depth of the Microsoft Cloud. We’ll continue to invest in our cloud and AI infrastructure while scaling with growing demand so we can lead the AI platform wave. And finally, we’ll align our costs with growth as we are committed to driving operating leverage.\n",
    "With that, let’s go to Q&A, Brett. \n",
    "BRETT IVERSEN: Thanks, Amy. We’ll now move over to Q&A. Out of respect for others on the call, we request that participants please only ask one question. Joe, can you please repeat your instructions? \n",
    "(Operator Direction.)\n",
    "KEITH WEISS, Morgan Stanley: Excellent. Thank you guys for taking the question and very nice end to a great fiscal year. \n",
    "Satya, you started out your comments talking about how every customer conversation has the customer asking you about utilizing generative AI technology and how fast they could utilize that generative AI technology. What’s the answer? What do you tell them in terms of the pace with which that could get into the marketplace and your customers could start using it? \n",
    "And then for Amy, how should investors think about just the fundamental gross margins behind these generative AI technologies? We understand there’s going to be a lot of CapEx to ramp up underneath these, but what should we expect in terms of what the ultimate gross margin looks like underneath all these new generative AI solutions? Thank you. \n",
    "SATYA NADELLA: Thank you, Keith, for the question. The fundamental guidance and conversation that we have with customers is twofold. One is the easiest path to value or generative AI is to adopt certain solutions. For example, GitHub Copilot, in some sense, it’s sort of the no brainer to add productivity leverage for all of the software developers in any organization. Whether you’re a bank, you’re a retailer or you’re a software company, it applies to everyone. That’s probably one of the things that we are seeing very good even productivity data and great adoption. \n",
    "And then obviously the excitement that there is already around the M365 Copilot. First thing we sort of talked about is how we ourselves are deploying all these copilots across, whether it’s Sales Copilot or M365 Copilot or GitHub Copilot, how do you get maximum value out of these horizontal toolchain? \n",
    "And then on top of that, we have taken what we did underneath these products and built it out as a first-class tech stack, which we talked about at our developer conference called the Copilot Stack, and then with Azure AI tooling, made it possible for someone like Moody’s or to build their own copilot for their people. To us, we want to be able to help customers build their generative AI applications on top of Azure AI and with speed, if you will. \n",
    "And so, those are the two things that we asked them to identify where they can get the maximum productivity leverage, and then we even swarm with our own resources to help them get those things done. \n",
    "And the last comment I’d make is the cloud and data in the cloud enables all this, because I think the diffusion cycle here is, in some sense, we have a new set of cloud meters that are getting adopted faster because of everything else that came before it in the cloud. Those would be the observations. \n",
    "AMY HOOD: And to your question, Keith, on gross margins and how I think about those, going forward, the first thing I would say is I expect gross margins here to transition over time, just like they did in the prior cloud transition. I would also say I expect workloads and the gross margins of the workloads to be different, just like they are in the cloud today. \n",
    "I would also add one thing that’s different than last time, we’ve talked a bit about this before, is that we start out in a different place with more of a shared platform, which allows us to scale those gross margins a bit faster than last time. And we do expect, as you asked and Satya talked about, the pace of this adoption curve, we do expect to be faster. You’re seeing the CapEx spend accelerate in Q4 and then again in Q1. And we’ve talked about what it should look like the rest of the year. \n",
    "Now that being said, we’re talking about all that and going through that transition while delivering in FY24 over FY23, effectively a point higher operating margins, because if it’s flat year over year, as we guided, with the headwind from the useful life change, when you correct for that, it’s about a point higher. \n",
    "I think the real focus here is being able to be aggressive in meeting the demand curve and focusing on the transition, and growth and gross margins, and delivering the operating leverage. \n",
    "KEITH WEISS: Excellent. Thank you, guys. \n",
    "BRETT IVERSEN: Thanks, Keith. Operator, next question, please.\n",
    "(Operator Direction.)\n",
    "BRENT THILL, Jeffries: Thank you. Satya, on the optimization headwinds that you continue to see, when do you think we hit peak optimization? Are we getting close to hitting that peak and getting some relief in the back half of the year and maybe AI helping provide as a tailwind? Any color from what you’re seeing from your perspective would be helpful.\n",
    "SATYA NADELLA: Sure, Brent. Thank you for the question. Yeah, a couple of observations. One is I think overall in the cloud, you do see new project starts and then those project starts get optimized. And then you sort of time series all of that, and that’s sort of what you see in the normal course. What happened here was during the pandemic, obviously, there were lots of new projects starts and optimization, in some sense, was postponed. And that’s where you’re seeing, I’ll call it, catch up optimization. And that’s something that, to your point, we will lap going into the next couple of quarters – I think it’ll come down – and we are seeing new projects starts, both traditional types of projects starts, even cloud migrations, data applications, and of course, obviously, the AI applications.\n",
    "But we’ll get back to, I’ll call it, the normal pace of new project starts and optimizations, going forward. But we will cycle through, I think in the next couple of quarters, what is the last catch up optimization. \n",
    "AMY HOOD: I would just add, Brent, I think, to Satya’s point, and maybe to build a bit of a line for, I think it felt very similar to last quarter where we made the same comments, which is we’re seeing sort of the normal optimization plus we’re seeing new workload starts across these workloads Satya talked about. And I think that’s what we’re saying, going forward, and really what the change is just that lapping of, I think, a bit of a catch up from a year ago. And you’re right, we’ll continue to do that through H2. \n",
    "BRENT THILL: Thanks. \n",
    "BRETT IVERSEN: Thanks, Brent. Operator, next question, please.\n",
    "(Operator Direction.)\n",
    "MARK MOERDLER, Bernstein Research: Thank you very much for taking the question and congrats on the quarter. \n",
    "\n",
    "Amy, CapEx moved up significantly Q over Q and year over year, and it’s increasing moving forward. Can you give us some color? Is it physical datacenters? Is this predominantly servers? Is it predominantly AI driven? How should we think about the useful life?\n",
    "And then, quickly for Satya, can you give us some status on the general availability of the full copilot development stack and how long it’s taking clients and partners to build copilots? Thanks. \n",
    "AMY HOOD: Why don’t I start on the CapEx question, Satya, then I’ll turn it over to you.\n",
    "Mark, really, first of all, both in Q4 and then talking about Q1, the acceleration is really quite broad. It’s both on the datacenters and the physical basis, plus CPUs and GPUs, and networking equipment. Think of it in a broad sense as opposed to a narrow sense. It’s overall increases of acceleration of overall capacity. \n",
    "And I think if you look back over really FY23, you wouldn’t have seen some of the pace on normal, what I would say capacity adds, even for the normal Azure workload. You’re seeing both accelerations and normal Azure workloads plus some of the AI workloads, is partially the reason. It’s why I do comment quite often that it’s both overall commercial cloud demand and building out capacity for AI; it’s both.\n",
    "\n",
    "SATYA NADELLA: Yeah, and I think, just for perspective, I think it’s sort of always good to think about it, right, where we have, what, 111 commercial cloud business growing at 22%, year over year. And then you had a CapEx growth which was around the same number, 23%-24%. In some sense, it’s sort of replacement capital plus some new capital that is going to drive new growth. That’s, I think, the scale, and we feel good about that structure of overall growth rates and how it translates into future TAM opportunity for us.\n",
    "And then, to your other question on how all this translates into project starts effectively, the Copilot Stack is available today on Azure. We have everything from Azure AI toolchain where you can use, obviously, Azure OpenAI, or even you can use open models from LLaMa and other Hugging Face models. You have all the Fabric and all of our operational data stores for what is one of the most useful patterns around generative AI, is what is called retrieval augmented generation, which is you take the data that you have in the data stores, use it in a prompt to generate completions, summaries, what have you. And so, that’s something that we’re seeing a lot of, and the copilots are fundamentally orchestrations of that. And so, we have all of these services available. \n",
    "We see the thing that’s fascinating is when you use something like Power Virtual Agent, you have a low-code, no-code tool to build, effectively, these AI products or full-fledged copilots like we’ve built. And all of the underlying primitives for that are available on Azure. The toolchain is available on Azure, and the speed with which customers are able to deploy them, ISVs are able to build them is pretty impressive. \n",
    "MARK MOERDLER: Thank you, I appreciate it.\n",
    "BRETT IVERSEN: Thanks, Mark. Operator, next question, please. \n",
    "(Operator Direction.)\n",
    "KASH RANGAN, Goldman Sachs: Hi, thank you very much. Congratulations on the quarter. If I could, I just wanted to get your thoughts, shift the discussion away from COGS and CapEx to more of the top line outlook. \n",
    "It looks like Azure growth rate is definitely starting to stabilize, and generative AI contribution to Azure is measurably improving, quarter by quarter. And optimization in a broader sense is also starting to settle down. Where does this leave with the company’s outlook for Azure growth rate in the future quarters? Are we at a point where we bottomed out, and we could start to see some acceleration due to the trends we discussed? \n",
    "And also, if you take the superset of Microsoft Cloud, when you throw in the new pricing for copilot, certainly looks like the TAMs are opening up in a pretty significant way. When you take that broader lens, that 21%- 22% growth rate that Satya and Amy referred to, what could be the outlook? Could we be too optimistic in entertaining hopes of some kind of acceleration in the years ahead, or how do you think about that, the outlook on the top line? Thank you so much.\n",
    "SATYA NADELLA: Sure, Kash. Thanks for the question. Maybe I’ll start and then, Amy, you can add because I think we do think about what’s the long-term TAM here, right? I mean, you’ve heard me talk about this as a percentage of GDP. What’s going to be tech spend? If you believe that, let’s say the 5% of GDP is going to go to 10% of GDP, maybe that gets accelerated because of the AI wave. Then the question is how much of that goes to the various parts of our commercial cloud? And then how competitive are we in each layer, right? \n",
    "If you sort of break it down, you talked about how Microsoft 365, we think of this copilot as a third pillar, right? We had the creation tools. We then had all the communication and collaboration services, and we think the AI copilot is a third pillar. We are excited about it. Amy talked about how we want to get it out first as part of this preview, and then in the second half of the next fiscal year, we’ll start getting some of the real revenue signal from it. We’re looking forward to it, but we think of it long term as a third pillar, like we thought about something like, say, Teams or SharePoint back in the day, or what have you. \n",
    "\n",
    "Then Azure, the way I think about it is we still are, whatever, inning two or inning three of even the cloud migration, especially if you view it, right, whether by industry moves to the cloud, segment move to the cloud as well as country adoption of the cloud. There’s still early innings of the cloud migration itself. There’s a lot there still. And then on top of that, there is this completely new world of AI driving a set of new workloads. \n",
    "And so, we think of that, again, being pretty expansive from a TAM opportunity, and we’ll play it out. But at the same time, as we are $110- $111 billion commercial cloud that has grown in 20s. And so, therefore, we do hit law of large numbers. But that said, we do think that this is a business that can have sustained high growth, which is something that we are excited about. \n",
    "AMY HOOD: And I think the only thing, Kash, I would add is I think in some ways, what we’re really pointing to is there’s a process here. We see the demand signal is quite strong; it remains strong. I’m thrilled with all the product announcements we’ve made. I’m thrilled with them moving to preview and then moving to GA. They absolutely are expansive in terms of addressable market. They reach new budget pools, is almost the way I talk about it a lot in terms of how CIOs or CFOs that I talk to think about that investment, so a growing opportunity.\n",
    "\n",
    "And as you know, we’re focused on executing against that. And then revenue is an outcome, but it certainly does require the demand signal, requires the capital expense and then creates the opportunity. And that’s why I think in some ways, we’re spending a little more time talking about some of that investment, is because it is the demand signal. \n",
    "KASH RANGAN: Awesome. Thank you so much. \n",
    "BRETT IVERSEN: Thanks, Kash. Operator, next question, please. \n",
    "(Operator Direction.)\n",
    "KARL KEIRSTEAD, UBS: Okay, great. Amy, if I could double-click a little bit on the exciting news around M365 Copilot, as everybody on the line looks to layer that opportunity into our models, I just wanted to get your views. Are there any guardrails you’d offer us to sort of keep us in line? Is there a degree of gross margin pressure in the Office segment? \n",
    "In other words, is it a fairly cost intensive new product that we should keep in mind? And also, could it pull along Azure in the sense that you need Azure AD and perhaps some of the other cybersecurity products? A little color there might help everybody with their modeling exercise tonight and in the coming weeks.\n",
    "AMY HOOD: Thanks, Karl. I think maybe I’ll first start with the process we have when we release new products. And I absolutely understand we are excited, too, by the demand signal, the customer reaction, really the requests for getting to be in the paid preview. It’s all encouraging. \n",
    "As you know, last week, we announced pricing. Then we’ll continue to work through the paid preview process, get good feedback. Then we’ll announce the general availability date. Then we’ll get to the GA date. Then we’ll, of course, be able to sell it and then recognize revenue. And that is why I continue to say that I am just as excited as everyone else about this, and it should be more H2 weighted. And we’ve, I think, given you some sizing opportunities and I think I would use all that. But I do think this is really about pacing. And, of course, we’ve still got to get our Security Copilot and some of the Dynamics workloads priced and released, and we’ll continue to work toward that. \n",
    "And, of course, I think one of the things that people often, I think, overlook is, and Satya mentioned it briefly, when you go back to the pull along Azure, I think in many ways, lots of these AI products pull along Azure because it’s not just the AI solution services that you need to build an app. And so, it’s less about Microsoft 365 pulling it along or any one copilot. It’s that when you’re building these, it requires data, and it requires the AI services. You’ll see them pull both core Azure and AI Azure along with them. And I think that’s an important nuance as well. \n",
    "\n",
    "SATYA NADELLA: Yeah, and if I could just add to what Amy said, the platform effect here is really all about the extensibility of the copilots. You see that today when people build applications in Teams that are built on Power Apps, and those Power Apps happen to use something like SQL DB on Azure. That’s like a classic line of business extension. You’ll see the same thing. When I have a copilot plug in, that plug in uses Azure AI, Azure meters, Azure data sources, Azure Semantic Search. You’ll see, obviously, a pull through not only on the identity or security layer, but in the core PaaS services of Azure plus the copilot extensibility in M365. \n",
    "KARL KEIRSTEAD: Terrific, thank you. \n",
    "BRETT IVERSEN: Thanks, Karl. Operator, our next question, please. \n",
    "(Operator Direction.)\n",
    "MARK MURPHY, JP Morgan: Yes, thank you very much. Satya, there’s so much evidence now that GitHub Copilot is boosting developer productivity by 40% to 50% or more, and it’s resulting in higher quality code. Do you envision a similar level of productivity boost for the Microsoft 365 Copilot or the Security Copilot, the Sales Copilot? In other words, can every room in the house be remodeled to a similar extent such that that value proposition is pretty elevated across the entire stack?\n",
    "SATYA NADELLA: Yeah, Judson Althoff would love you for having used his metaphor of remodeling every room of the house with AI, because you’re absolutely right. I mean, that’s the opportunity we see. I think what you’re also referencing is now, there is good empirical evidence and data around the GitHub Copilot and the productivity stats around it. And we’re actively working on that for M365 Copilot, also for things like the role-based ones like Sales Copilot, our Service Copilot. We see these business processes having very high productivity gains. \n",
    "And so, yes, over the course of the year, we will have all of that evidence. And I think at the end of the day, as Amy referenced, every CFO and CIO is also going to take a look at this. I do think for the first time, or rather, I do think people are going to look at how can they complement their OpEx spend with essentially these copilots in order to drive more efficiency and, quite frankly, even reduce the burden and drudgery of work on their OpEx and their people, and so on. Therefore, I think you’re going to see all of that translated into productivity stats, and we’re looking forward to getting that data out. \n",
    "MARK MURPHY: Thank you very much. \n",
    "BRETT IVERSEN: Thanks, Mark. Operator, next question, please. \n",
    "(Operator Direction.) \n",
    "ALEX ZUKIN, Wolfe Research: Hey, guys. Thanks for taking the question. I guess maybe just a multi-part. You mentioned a couple of times that with the AI workload adoption that you’re seeing on Azure, it’s starting to look maybe a little bit different from an incremental share gain perspective versus previous generations. Can you maybe expand upon that? How should that drive for Azure consumption, particularly as we get through the year? \n",
    "And do you see a scenario where either the combination of lapping the optimization headwind plus the AI contribution plus this incremental tailwind that you’re seeing around the workloads actually does drive re-acceleration in Azure, particularly in the second half when you’re going to start to see some of those things kick in?\n",
    "SATYA NADELLA: Yeah. I mean, the thing that we are both seeing and excited about is both the new workloads. I mean, if you think about Azure, we have grown Azure over the years, coming from behind. And here we are, as a strong number two in the lead when it comes to these new workloads. \n",
    "For example, we are seeing new logos. Customers who may have used another cloud for most of what they do are, for the first time, sort of starting to use Azure for some of their new AI workloads. We also have even customers who have used multiple clouds, who’ve used us for a class of sort of workloads, also start new projects when it’s in data and AI, which they were using other clouds for. \n",
    "What I think you will see us is more share gains, more logo gains, reducing our TAC even. And so, those are the things, the points of leverage. But at the same time, we are not a small business anymore in any of these things. We are of significant scale. And so, yes, we celebrate. That’s why we’re even giving you the visibility or one point of it showing up this quarter, a couple of points showing up next quarter. And those are material numbers. \n",
    "And so, that’s kind of what I think we’ll track. And I think Amy mentioned it because there are two parts to even the AI, right? There is the models themselves with our partnership with OpenAI. That’s sort of one type of spend on compute and the other is much more revenue driven, right, which is we will track the inference costs to the revenue and demand. And you’re already seeing both of those play out. \n",
    "ALEX ZUKIN: Thank you.\n",
    "BRETT IVERSEN: Thanks, Alex. Operator, we have time for one last question.\n",
    "(Operator Direction.)\n",
    "KIRK MATERNE, Evercore: Yeah, thanks for squeezing me in. Satya, I was wondering if you could expand a little bit on your comments on data platforms. I think we’ve heard a lot over the last quarter or so about if you don’t have a data strategy, it’s tough to have an AI strategy. \n",
    "Can you just talk about where customers are right now in that journey to have a more, I guess, thoughtful data strategy? And what does that mean in terms of their ability to adopt AI services, meaning do they have to sort of tackle the data issue first before they can really take advantage of all the AI services, or how should we think about that sort of juxtaposition? Thanks. \n",
    "SATYA NADELLA: Yeah, sure. Thank you for the question. Yes, absolutely, I think having your data, in particular in the cloud, is sort of key to how you can take advantage of essentially these new AI reasoning engines to complement, I’ll call it, your databases, because these AI engines are not databases. But they can reason over your data and to help you then get more insights, more completions, more predictions, more summaries and what have you. Those are the things, when we say copilot design pattern, that’s sort of what that design pattern is all about. \n",
    "The thing that perhaps even in the last quarter, and I had that in my remarks, is most exciting is how, with Microsoft Fabric, especially for the analytics workloads, we’ve brought together compute, storage, governance with a very disruptive business model. \n",
    "I mean, to give you a flavor for it, right, you have your data in an Azure data lake. You can bring SQL compute to it. You can bring Spark to it. You can bring Azure AI or Azure OpenAI to it, right? The fact is you have storage separated from all these compute meters, and they’re all interchangeable, right? You don’t have to buy each of these separately. That’s the disruptive business model. \n",
    "I feel that Microsoft is very well positioned with the way our data architecture lays out, our business model around data, and how people will plan to use data with AI services. That’s kind of what I mean by getting your data estate in order, and it’s just not getting data estate in order, but you have to have it structured such that you can have the flexibility that allows you to exercise the data and compute in combinations that make sense for this new age. \n",
    "BRETT IVERSEN: Thanks, Kirk. That wraps up the Q&A portion of today’s earnings call. Thank you for joining us today, and we look forward to speaking with all of you soon. \n",
    "SATYA NADELLA: Thank you, all.\n",
    "AMY HOOD: Thank you, all. \n",
    "(Operator Direction.)\n",
    "END\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "print(summarizer(ARTICLE, max_length=130, min_length=30, do_sample=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
